{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nipunikajain/ExperimentsWithLLM/blob/main/Chatbot_SEC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "YC4R6nkCp91d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YC4R6nkCp91d",
        "outputId": "03dff194-11a4-40bc-edb6-98d42c7fd4ef",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-13 16:57:22--  https://www.dropbox.com/s/948jr9cfs7fgj99/UBER.zip?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.64.18, 2620:100:6031:18::a27d:5112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.64.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/dl/948jr9cfs7fgj99/UBER.zip [following]\n",
            "--2023-04-13 16:57:24--  https://www.dropbox.com/s/dl/948jr9cfs7fgj99/UBER.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc922615c1eb3015ea3e5e35de50.dl.dropboxusercontent.com/cd/0/get/B6FMIcXSFGF-KK6zL5aTugcr0yoPkxNMofh-N7TpnOEVcCQII-2WKo8dQTRpGm-HfdpmfEpBn8OKpkjHQGfBurfqvUplQ-lCzuozti6pwuBELVl2kxynHNYo5nJrPiBHvgaWI1U8fQDOGoQoRS_lPEvfWtZ73oP9pk-rWduXvYvWvg/file?dl=1# [following]\n",
            "--2023-04-13 16:57:28--  https://uc922615c1eb3015ea3e5e35de50.dl.dropboxusercontent.com/cd/0/get/B6FMIcXSFGF-KK6zL5aTugcr0yoPkxNMofh-N7TpnOEVcCQII-2WKo8dQTRpGm-HfdpmfEpBn8OKpkjHQGfBurfqvUplQ-lCzuozti6pwuBELVl2kxynHNYo5nJrPiBHvgaWI1U8fQDOGoQoRS_lPEvfWtZ73oP9pk-rWduXvYvWvg/file?dl=1\n",
            "Resolving uc922615c1eb3015ea3e5e35de50.dl.dropboxusercontent.com (uc922615c1eb3015ea3e5e35de50.dl.dropboxusercontent.com)... 162.125.69.15, 2620:100:6031:15::a27d:510f\n",
            "Connecting to uc922615c1eb3015ea3e5e35de50.dl.dropboxusercontent.com (uc922615c1eb3015ea3e5e35de50.dl.dropboxusercontent.com)|162.125.69.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1820227 (1.7M) [application/binary]\n",
            "Saving to: ‘data/UBER.zip’\n",
            "\n",
            "data/UBER.zip       100%[===================>]   1.74M  1.19MB/s    in 1.5s    \n",
            "\n",
            "2023-04-13 16:57:31 (1.19 MB/s) - ‘data/UBER.zip’ saved [1820227/1820227]\n",
            "\n",
            "Archive:  data/UBER.zip\n",
            "   creating: data/UBER/\n",
            "  inflating: data/UBER/UBER_2021.html  \n",
            "  inflating: data/__MACOSX/UBER/._UBER_2021.html  \n",
            "  inflating: data/UBER/UBER_2020.html  \n",
            "  inflating: data/__MACOSX/UBER/._UBER_2020.html  \n",
            "  inflating: data/UBER/UBER_2019.html  \n",
            "  inflating: data/__MACOSX/UBER/._UBER_2019.html  \n",
            "  inflating: data/UBER/UBER_2022.html  \n",
            "  inflating: data/__MACOSX/UBER/._UBER_2022.html  \n"
          ]
        }
      ],
      "source": [
        "# download files\n",
        "!mkdir data\n",
        "!wget \"https://www.dropbox.com/s/948jr9cfs7fgj99/UBER.zip?dl=1\" -O data/UBER.zip\n",
        "!unzip data/UBER.zip -d data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "CuHeyb224pI2",
      "metadata": {
        "id": "CuHeyb224pI2"
      },
      "outputs": [],
      "source": [
        "# set text wrapping\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "QaFX6KfIz-Zn",
      "metadata": {
        "id": "QaFX6KfIz-Zn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "18f4db67-6477-460f-e738-5f24a3e034f4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = \"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\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 906
        },
        "id": "YN4-IUCCjJu3",
        "outputId": "58e00992-fdd7-4ea5-89eb-e8d365b7a19b"
      },
      "id": "YN4-IUCCjJu3",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting llama_index\n",
            "  Downloading llama_index-0.5.15.tar.gz (175 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.5/175.5 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: dataclasses_json in /usr/local/lib/python3.9/dist-packages (from llama_index) (0.5.7)\n",
            "Requirement already satisfied: langchain>=0.0.123 in /usr/local/lib/python3.9/dist-packages (from llama_index) (0.0.139)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from llama_index) (1.22.4)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.9/dist-packages (from llama_index) (8.2.2)\n",
            "Requirement already satisfied: openai>=0.26.4 in /usr/local/lib/python3.9/dist-packages (from llama_index) (0.27.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from llama_index) (1.5.3)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.9/dist-packages (from llama_index) (0.3.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.9/dist-packages (from langchain>=0.0.123->llama_index) (2.27.1)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.9/dist-packages (from langchain>=0.0.123->llama_index) (3.8.4)\n",
            "Requirement already satisfied: SQLAlchemy<2,>=1 in /usr/local/lib/python3.9/dist-packages (from langchain>=0.0.123->llama_index) (1.4.47)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.9/dist-packages (from langchain>=0.0.123->llama_index) (4.0.2)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /usr/local/lib/python3.9/dist-packages (from langchain>=0.0.123->llama_index) (1.2.4)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.9/dist-packages (from langchain>=0.0.123->llama_index) (6.0)\n",
            "Requirement already satisfied: gptcache>=0.1.7 in /usr/local/lib/python3.9/dist-packages (from langchain>=0.0.123->llama_index) (0.1.10)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.9/dist-packages (from langchain>=0.0.123->llama_index) (1.10.7)\n",
            "Requirement already satisfied: typing-inspect>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from dataclasses_json->llama_index) (0.8.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /usr/local/lib/python3.9/dist-packages (from dataclasses_json->llama_index) (3.19.0)\n",
            "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /usr/local/lib/python3.9/dist-packages (from dataclasses_json->llama_index) (1.5.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai>=0.26.4->llama_index) (4.65.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->llama_index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->llama_index) (2022.7.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.9/dist-packages (from tiktoken->llama_index) (2022.10.31)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.123->llama_index) (1.3.3)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.123->llama_index) (2.0.12)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.123->llama_index) (1.8.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.123->llama_index) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.123->llama_index) (22.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.123->llama_index) (6.0.4)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.9/dist-packages (from gptcache>=0.1.7->langchain>=0.0.123->llama_index) (5.3.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.9/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses_json->llama_index) (23.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic<2,>=1->langchain>=0.0.123->llama_index) (4.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->llama_index) (1.16.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2->langchain>=0.0.123->llama_index) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2->langchain>=0.0.123->llama_index) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2->langchain>=0.0.123->llama_index) (2022.12.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from SQLAlchemy<2,>=1->langchain>=0.0.123->llama_index) (2.0.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from typing-inspect>=0.4.0->dataclasses_json->llama_index) (1.0.0)\n",
            "Building wheels for collected packages: llama_index\n",
            "  Building wheel for llama_index (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama_index: filename=llama_index-0.5.15-py3-none-any.whl size=260128 sha256=3f662516fc77423c5978a7b8ffa5bbd5a741883f0dbeeb74bef798fc8e2a1281\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/bc/e8/32d6ccdfde89caa63784fccb0fc20903a22d5f6f9f45ed0e68\n",
            "Successfully built llama_index\n",
            "Installing collected packages: llama_index\n",
            "Successfully installed llama_index-0.5.15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rich==13.0.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "id": "MHNZCorhhet-",
        "outputId": "c5bfb360-2afb-4d92-c614-ac4f17d7948a"
      },
      "id": "MHNZCorhhet-",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rich==13.0.0\n",
            "  Downloading rich-13.0.0-py3-none-any.whl (238 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.1/238.1 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting commonmark<0.10.0,>=0.9.0\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.9/dist-packages (from rich==13.0.0) (2.14.0)\n",
            "Installing collected packages: commonmark, rich\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.3.3\n",
            "    Uninstalling rich-13.3.3:\n",
            "      Successfully uninstalled rich-13.3.3\n",
            "Successfully installed commonmark-0.9.1 rich-13.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3a5cb155-cfe0-4c89-a2b4-c61d5b7cbe61",
      "metadata": {
        "id": "3a5cb155-cfe0-4c89-a2b4-c61d5b7cbe61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "bc0bbfda-8686-42cb-f27f-94bc2964ba4d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from gpt_index import download_loader, GPTSimpleVectorIndex, ServiceContext\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "354ddbdf-0045-474b-b6f2-1b4c22ad360a",
      "metadata": {
        "id": "354ddbdf-0045-474b-b6f2-1b4c22ad360a",
        "tags": []
      },
      "source": [
        "### Ingest Unstructured Data Through the Unstructured.io Reader\n",
        "\n",
        "Leverage the capabilities of Unstructured.io HTML parsing.\n",
        "Downloaded through LlamaHub."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "61fed4f1-8cca-4d98-b916-a3184279e256",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "61fed4f1-8cca-4d98-b916-a3184279e256",
        "outputId": "eca8094e-afaa-4071-f8b3-5d4976bc876e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "years = [2022, 2021, 2020, 2019]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "0371970e-c11c-4534-aa22-7cfdfe411bb3",
      "metadata": {
        "id": "0371970e-c11c-4534-aa22-7cfdfe411bb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "1bf9a894-5e89-4af0-9ae9-5633cfa57cfd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "UnstructuredReader = download_loader(\"UnstructuredReader\", refresh_cache=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "29084a11-f3da-428d-ae17-27b85a365e84",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "29084a11-f3da-428d-ae17-27b85a365e84",
        "outputId": "f6f990a6-836c-4bfb-bb0a-185d0a72851b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ],
      "source": [
        "loader = UnstructuredReader()\n",
        "doc_set = {}\n",
        "all_docs = []\n",
        "for year in years:\n",
        "    year_docs = loader.load_data(file=Path(f'./data/UBER/UBER_{year}.html'), split_documents=False)\n",
        "    # insert year metadata into each year\n",
        "    for d in year_docs:\n",
        "        d.extra_info = {\"year\": year}\n",
        "    doc_set[year] = year_docs\n",
        "    all_docs.extend(year_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08b367eb-f9cc-449a-99c5-dfcfbef20a9d",
      "metadata": {
        "id": "08b367eb-f9cc-449a-99c5-dfcfbef20a9d"
      },
      "source": [
        "### Setup a Vector Index for each SEC filing\n",
        "\n",
        "We setup a separate vector index for each SEC filing from 2019-2022.\n",
        "\n",
        "We also optionally initialize a \"global\" index by dumping all files into the vector store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "8fbe18a6-4a08-441d-adae-a6195f2cdcb1",
      "metadata": {
        "id": "8fbe18a6-4a08-441d-adae-a6195f2cdcb1",
        "outputId": "6d284854-3bd6-4cf3-ca6b-76fa8aa88a6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# initialize simple vector indices + global vector index\n",
        "# NOTE: don't run this cell if the indices are already loaded! \n",
        "index_set = {}\n",
        "service_context = ServiceContext.from_defaults(chunk_size_limit=512)\n",
        "for year in years:\n",
        "    cur_index = GPTSimpleVectorIndex.from_documents(doc_set[year], service_context=service_context)\n",
        "    index_set[year] = cur_index\n",
        "    cur_index.save_to_disk(f'index_{year}.json')\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "d3a5e993-99ae-445a-bcae-e2d415d84e34",
      "metadata": {
        "id": "d3a5e993-99ae-445a-bcae-e2d415d84e34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "58dc3a4f-0901-498f-bcfa-a0a2522f0034"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Load indices from disk\n",
        "index_set = {}\n",
        "for year in years:\n",
        "    cur_index = GPTSimpleVectorIndex.load_from_disk(f'index_{year}.json')\n",
        "    index_set[year] = cur_index"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "007a99d7-4f63-44bf-957b-c9f5669bce28",
      "metadata": {
        "id": "007a99d7-4f63-44bf-957b-c9f5669bce28"
      },
      "source": [
        "### Composing a Graph to synthesize answers across 10-K filings (2019-2022)\n",
        "\n",
        "We want our queries to aggregate/synthesize information across *all* 10-K filings. To do this, we define a List index\n",
        "on top of the 4 vector indices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "f3fb341a-19a3-4e4a-9369-7ddc46b8c2a6",
      "metadata": {
        "id": "f3fb341a-19a3-4e4a-9369-7ddc46b8c2a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "46ac4221-2e44-4399-af96-1c2d8e320960"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from gpt_index import GPTListIndex, LLMPredictor\n",
        "from langchain import OpenAI\n",
        "from gpt_index.indices.composability import ComposableGraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "966388cb-2fe4-4427-ad2e-cea6a0375233",
      "metadata": {
        "id": "966388cb-2fe4-4427-ad2e-cea6a0375233",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "8cadcf4e-b56e-491d-b44e-bc494a4b6287"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# set summary text for each doc\n",
        "index_summaries = [f\"UBER 10-k Filing for {year} fiscal year\" for year in years]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "f9e453b1-6782-45b5-8258-dfc386e6cf22",
      "metadata": {
        "id": "f9e453b1-6782-45b5-8258-dfc386e6cf22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "4187d959-5454-4d63-ef68-29977544725b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# set number of output tokens\n",
        "llm_predictor = LLMPredictor(llm=OpenAI(temperature=0, max_tokens=512))\n",
        "service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "3b758fc2-bb21-46da-91b5-53e399eecfb0",
      "metadata": {
        "id": "3b758fc2-bb21-46da-91b5-53e399eecfb0",
        "outputId": "48b6e39e-96d9-4e77-e964-c48b91674f14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# define a list index over the vector indices\n",
        "# allows us to synthesize information across each index\n",
        "graph = ComposableGraph.from_indices(\n",
        "    GPTListIndex, \n",
        "    [index_set[y] for y in years], \n",
        "    index_summaries=index_summaries,\n",
        "    service_context=service_context\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "NLtnE--Mya7P",
      "metadata": {
        "id": "NLtnE--Mya7P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "e49368ad-ab99-4c07-8a8a-0ffc61838ea2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "graph.save_to_disk('10k_graph.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "b92a0ba3-5c6b-485f-8f8d-5e164689ff05",
      "metadata": {
        "id": "b92a0ba3-5c6b-485f-8f8d-5e164689ff05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "0ab1e341-f197-4575-967e-fe11b297b470"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "graph = ComposableGraph.load_from_disk('10k_graph.json', service_context=service_context)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e2edef1-005f-4733-b64c-5987efa4c88d",
      "metadata": {
        "id": "7e2edef1-005f-4733-b64c-5987efa4c88d"
      },
      "source": [
        "## Setting up the Chatbot Agent\n",
        "\n",
        "We use Langchain to define the outer chatbot abstraction. We use LlamaIndex as a core Tool within this abstraction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "6c2de0f3-9ec3-4f80-bd36-a509f8bfd4b8",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "6c2de0f3-9ec3-4f80-bd36-a509f8bfd4b8",
        "outputId": "e5b4f6ae-b240-4281-87d9-bae200a9a7a3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from langchain.agents import Tool\n",
        "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.agents import initialize_agent\n",
        "\n",
        "from gpt_index.langchain_helpers.agents import LlamaToolkit, create_llama_chat_agent, IndexToolConfig, GraphToolConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "c9a6faa1-dc06-4d9c-98b4-06e7ee19c559",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "c9a6faa1-dc06-4d9c-98b4-06e7ee19c559",
        "outputId": "1caba777-033e-4566-9a1b-4bc9d79eda0f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# define a decompose transform\n",
        "from gpt_index.indices.query.query_transform.base import DecomposeQueryTransform\n",
        "decompose_transform = DecomposeQueryTransform(\n",
        "    llm_predictor, verbose=True\n",
        ")\n",
        "\n",
        "# define query configs for graph \n",
        "query_configs = [\n",
        "    {\n",
        "        \"index_struct_type\": \"simple_dict\",\n",
        "        \"query_mode\": \"default\",\n",
        "        \"query_kwargs\": {\n",
        "            \"similarity_top_k\": 1,\n",
        "            # \"include_summary\": True\n",
        "        },\n",
        "        \"query_transform\": decompose_transform\n",
        "    },\n",
        "    {\n",
        "        \"index_struct_type\": \"list\",\n",
        "        \"query_mode\": \"default\",\n",
        "        \"query_kwargs\": {\n",
        "            \"response_mode\": \"tree_summarize\",\n",
        "            \"verbose\": True\n",
        "        }\n",
        "    },\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "e763ceba-1c54-4abb-9589-c0628d18c5e5",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "e763ceba-1c54-4abb-9589-c0628d18c5e5",
        "outputId": "0880d42a-b278-4814-9b29-8c0e6db7b2f7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# define toolkit\n",
        "index_configs = []\n",
        "for y in range(2019, 2023):\n",
        "    tool_config = IndexToolConfig(\n",
        "        index=index_set[y], \n",
        "        name=f\"Vector Index {y}\",\n",
        "        description=f\"useful for when you want to answer queries about the {y} SEC 10-K for Uber\",\n",
        "        index_query_kwargs={\"similarity_top_k\": 3},\n",
        "        tool_kwargs={\"return_direct\": True}\n",
        "    )\n",
        "    index_configs.append(tool_config)\n",
        "    \n",
        "# graph config\n",
        "graph_config = GraphToolConfig(\n",
        "    graph=graph,\n",
        "    name=f\"Graph Index\",\n",
        "    description=\"useful for when you want to answer queries that require analyzing multiple SEC 10-K documents for Uber.\",\n",
        "    query_configs=query_configs,\n",
        "    tool_kwargs={\"return_direct\": True}\n",
        ")\n",
        "\n",
        "toolkit = LlamaToolkit(\n",
        "    index_configs=index_configs,\n",
        "    graph_configs=[graph_config]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "c28cd7ee-15ef-4240-aff3-ecc0ba335df2",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "c28cd7ee-15ef-4240-aff3-ecc0ba335df2",
        "outputId": "32e7336a-505d-46ba-8ed4-e9eb578fb7c8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
        "llm=OpenAI(temperature=0)\n",
        "agent_chain = create_llama_chat_agent(\n",
        "    toolkit,\n",
        "    llm,\n",
        "    memory=memory,\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "92bd0eaa-73ad-4735-8234-a376fd1b3a6a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "92bd0eaa-73ad-4735-8234-a376fd1b3a6a",
        "outputId": "662e9873-1f51-46a1-dc4f-5cc432e79046"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Thought: Do I need to use a tool? No\n",
            "AI: Hi Nipunika, nice to meet you! How can I help you today?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hi Nipunika, nice to meet you! How can I help you today?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "agent_chain.run(input=\"hi, i am Nipunika\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "19ca8476-bfeb-4c88-a0ff-15424e2d91c7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "19ca8476-bfeb-4c88-a0ff-15424e2d91c7",
        "outputId": "0b1c44ba-4cc7-45b5-c56a-ae5194589c7c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Thought: Do I need to use a tool? Yes\n",
            "Action: Vector Index 2020\n",
            "Action Input: Revenue\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3m\n",
            "\n",
            "Revenue recognized under ASC 840 and ASC 842 for the year 2020 was $21 million, primarily from service fees paid by Delivery People and Merchants for use of the platform and related services to successfully complete a meal delivery service on the platform, as well as from freight transportation services provided to Shippers. We recognize revenue when a Delivery transaction is complete, and when the performance obligation is satisfied for freight transportation services. In the majority of transactions, the service fee paid by Merchants is a fixed percentage of the meal price, while the service fee paid by Delivery People is the difference between the delivery fee amount paid by the end-user and the amount earned by the Delivery People. We typically receive the service fee within a short period of time following the completion of a delivery, and invoice the Shipper upon satisfaction of the performance obligation for freight transportation services.\u001b[0m\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nRevenue recognized under ASC 840 and ASC 842 for the year 2020 was $21 million, primarily from service fees paid by Delivery People and Merchants for use of the platform and related services to successfully complete a meal delivery service on the platform, as well as from freight transportation services provided to Shippers. We recognize revenue when a Delivery transaction is complete, and when the performance obligation is satisfied for freight transportation services. In the majority of transactions, the service fee paid by Merchants is a fixed percentage of the meal price, while the service fee paid by Delivery People is the difference between the delivery fee amount paid by the end-user and the amount earned by the Delivery People. We typically receive the service fee within a short period of time following the completion of a delivery, and invoice the Shipper upon satisfaction of the performance obligation for freight transportation services.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# agent_chain.run(input=\"What were some of the biggest risk factors in 2020 for Uber?\")\n",
        "agent_chain.run(input=\"What was the revenue generated by Uber in 2020?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "05b5cd50-cf28-4ad1-b1c2-067f626bad93",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 743
        },
        "id": "05b5cd50-cf28-4ad1-b1c2-067f626bad93",
        "outputId": "c7736b90-5453-47c2-92b6-c27d2ce17476"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Thought: Do I need to use a tool? Yes\n",
            "Action: Graph Index\n",
            "Action Input: Compare/contrast the risk factors described in the Uber 10-K across years\u001b[0m\u001b[33;1m\u001b[1;3m> Current query: Compare/contrast the risk factors described in the Uber 10-K across years\n",
            "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query:  What are the risk factors described in the Uber 10-K for the 2022 fiscal year?\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3m> Current query: Compare/contrast the risk factors described in the Uber 10-K across years\n",
            "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query:  What are the risk factors described in the Uber 10-K for the 2021 fiscal year?\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3m> Current query: Compare/contrast the risk factors described in the Uber 10-K across years\n",
            "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query:  What are the risk factors described in the Uber 10-K for the 2020 fiscal year?\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3m> Current query: Compare/contrast the risk factors described in the Uber 10-K across years\n",
            "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query:  What are the risk factors described in the Uber 10-K for the 2019 fiscal year?\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m> Got node text: \n",
            "The risk factors described in the Uber 10-K for the 2022 fiscal year include: misclassification challenges that may impact the business, result of operations, financial position and operating cond...\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m> Got node text: \n",
            "The risk factors described in the Uber 10-K for the 2021 fiscal year include: the severity of the COVID-19 disease, the duration of the outbreak, any future waves or resurgences of the virus, vari...\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m> Got node text: \n",
            "The risk factors described in the Uber 10-K for the 2020 fiscal year include: any future waves or resurgences of the virus, variants of the virus, the timing of widespread adoption of vaccines aga...\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m> Got node text: \n",
            "Risk factors described in the Uber 10-K for the 2019 fiscal year include: competition from other ride-hailing and transportation companies; the impact of government regulation on the ride-hailing ...\n",
            "\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m\n",
            "The risk factors described in the Uber 10-K for the 2020, 2021, and 2022 fiscal years all include the potential legal challenges to the classification of Drivers as independent contractors. However, the risk factors for each year also include other potential risks that are unique to that year. For example, the 2020 fiscal year includes the potential for disruption due to the COVID-19 pandemic, while the 2021 fiscal year includes the potential for disruption due to the severity of the disease, the duration of the outbreak, and any future waves or resurgences of the virus. The 2022 fiscal year includes the potential for disruption due to misclassification challenges, the potential loss of flexibility under an employment model, and the potential inability to hire a majority of the Drivers currently using the platform.\u001b[0m\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nThe risk factors described in the Uber 10-K for the 2020, 2021, and 2022 fiscal years all include the potential legal challenges to the classification of Drivers as independent contractors. However, the risk factors for each year also include other potential risks that are unique to that year. For example, the 2020 fiscal year includes the potential for disruption due to the COVID-19 pandemic, while the 2021 fiscal year includes the potential for disruption due to the severity of the disease, the duration of the outbreak, and any future waves or resurgences of the virus. The 2022 fiscal year includes the potential for disruption due to misclassification challenges, the potential loss of flexibility under an employment model, and the potential inability to hire a majority of the Drivers currently using the platform.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "cross_query_str = (\n",
        "    \"Compare/contrast the risk factors described in the Uber 10-K across years. Give answer in bullet points.\"\n",
        ")\n",
        "\n",
        "agent_chain.run(input=cross_query_str)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a066a1c8-2108-447a-ab9a-b82b4f35696e",
      "metadata": {
        "id": "a066a1c8-2108-447a-ab9a-b82b4f35696e"
      },
      "source": [
        "### Setup Chatbot Loop Within Notebook\n",
        "\n",
        "We'll keep a running loop so that you can converse with the agent. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "f9dcd609-3921-493e-a4c1-3312dac277d2",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "f9dcd609-3921-493e-a4c1-3312dac277d2",
        "outputId": "7fe76bb0-0c43-4645-c5d1-8e7a7946302b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# reinitialize agent\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
        "llm=OpenAI(temperature=0)\n",
        "agent_chain = create_llama_chat_agent(\n",
        "    toolkit,\n",
        "    llm,\n",
        "    memory=memory,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "edf6b5a9-bac5-4599-93f8-21c2fc44fa4b",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "edf6b5a9-bac5-4599-93f8-21c2fc44fa4b",
        "outputId": "e1c8e1c3-9c4f-4fd3-deb2-ffcde9c846ee"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-d97c1d85dc7a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtext_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"User: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Agent: {response}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "while True:\n",
        "    text_input = input(\"User: \")\n",
        "    response = agent_chain.run(input=text_input)\n",
        "    print(f'Agent: {response}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50fa7bb1-817c-4ac1-af39-adbcb14139e2",
      "metadata": {
        "id": "50fa7bb1-817c-4ac1-af39-adbcb14139e2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "llama_index",
      "language": "python",
      "name": "llama_index"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}